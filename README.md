# â­ **AICONTENT â€“ Modular FastAPI AI Service Starter**

A fully structured, production-ready FastAPI + Celery microservice template for AI-powered workloads.
This project provides a scalable foundation for LLM content generation, background processing, SEO analysis, image suggestion, and calibration pipelines.

Designed for **containerized deployments**, **GitHub Actions**, and **Ansible orchestration**.

---

# ğŸ“Œ **Features**

* **FastAPI** application boilerplate with modular architecture
* **Celery Worker** for async/long-running tasks
* **Redis** as broker/cache
* **Pydantic v2** + `pydantic-settings` for clean environment handling
* **Structured Logging with Loguru**
* **Ruff + Black + isort + Pre-commit** enforcing code quality
* **Dockerized API + Worker images**
* **GitHub Actions CI/CD** with GHCR deployment
* Built-in folder structure for:

  * LLM providers
  * Content generation modules
  * SEO tools
  * Image suggestion
  * Calibration + personalization
  * Shared utilities
  * Prompt versioning and testing

---

# ğŸ“‚ **Project Structure**

```
aicontent/
â”œâ”€â”€ config/                     # App configuration
â”‚   â”œâ”€â”€ settings.py             # Pydantic v2 Settings
â”‚   â”œâ”€â”€ model_config.yaml
â”‚   â”œâ”€â”€ prompt_templates.yaml
â”‚   â””â”€â”€ logging_config.yaml
â”‚
â”œâ”€â”€ src/                        # Source code
â”‚   â”œâ”€â”€ main.py                 # FastAPI entry
â”‚   â”œâ”€â”€ celery_app.py           # Celery config
â”‚   â”œâ”€â”€ llm/                    # LLM provider abstraction
â”‚   â”œâ”€â”€ content/                # Content generation routes + services
â”‚   â”œâ”€â”€ images/                 # Image suggestion module
â”‚   â”œâ”€â”€ seo/                    # SEO analysis tools
â”‚   â”œâ”€â”€ calibration/            # Tone/style matching module
â”‚   â”œâ”€â”€ utils/                  # Logging, rate limiting, config loader
â”‚   â””â”€â”€ handlers/               # Global error handlers
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.api          # API image
â”‚   â”œâ”€â”€ Dockerfile.worker       # Celery worker image
â”‚   â””â”€â”€ docker-compose.yml      # Dev environment
â”‚
â”œâ”€â”€ tests/                      # Pytest test suite
â”‚
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚
â”œâ”€â”€ .github/workflows/          # CI/CD pipelines
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements-dev.txt
â”œâ”€â”€ README.md
â””â”€â”€ CHANGELOG.md
```

---

# âš™ï¸ **Installed Packages & Why**

### ğŸ”µ **FastAPI**

Modern async API framework for performance and developer experience.

### ğŸ”µ **Uvicorn + uvloop**

High-performance async server with event loop acceleration.

### ğŸ”µ **Pydantic v2**

Used for data validation & modeling.

### ğŸ”µ **pydantic-settings**

Pydantic v2 moved `BaseSettings` into this separate package.
Used for loading environment variables from `.env`.

### ğŸ”µ **python-dotenv**

Enables `.env` support outside Pydantic if needed.

### ğŸ”µ **PyYAML**

Loads YAML prompt templates, model configs, and other structured configs.

### ğŸ”µ **Celery**

Handles long-running async tasks (content generation, SEO processing, etc).

### ğŸ”µ **Redis**

Message broker + optional caching layer.

### ğŸ”µ **httpx + requests**

For async/sync HTTP calls to LLM APIs and partner services.

### ğŸ”µ **loguru**

Modern structured logging with better formatting and lower overhead than Python stdlib logging.

### ğŸ”µ **python-multipart**

Required by FastAPI for file uploads.

### ğŸ”µ **orjson**

Ultra-fast JSON parser used internally by FastAPI when available.

### ğŸ§ª **pytest + pytest-asyncio**

Included for robust unit + async testing.

---

# ğŸš€ **Getting Started (Local Development)**

### 1. Install dependencies

```bash
pip install -r requirements.txt
pip install -r requirements-dev.txt
```

### 2. Run API locally

```bash
uvicorn src.main:app --reload
```

### 3. Start Celery worker

```bash
celery -A src.celery_app worker --loglevel=INFO
```

### 4. Run tests

```bash
pytest -q
```

---

# ğŸ³ **Docker Usage**

### Build API

```bash
docker build -t aicontent-api -f docker/Dockerfile.api .
```

### Build Worker

```bash
docker build -t aicontent-worker -f docker/Dockerfile.worker .
```

### Run with Docker Compose

```bash
docker compose up --build
```

---

# ğŸ”„ **CI/CD (GitHub Actions + GHCR)**

This repo ships with:

### âœ” Build API Image

### âœ” Build Worker Image

### âœ” Push to GitHub Container Registry

### âœ” Automated Tests

### âœ” Automated Formatting + Linting

### âœ” Deploy with Ansible

The workflow files are located in:

```
.github/workflows/
â”œâ”€â”€ build.yml
â”œâ”€â”€ test.yml
â””â”€â”€ deploy.yml
```

---

# ğŸ” **Pre-commit Hooks (Code Quality Automation)**

Installed hooks:

* **Black** â€“ Auto-formatting
* **Ruff** â€“ Lint + autofix
* **Isort** â€“ Import sorting
* **Trailing whitespace fixer**
* **EOF fixer**
* **YAML/JSON validators**

Install locally:

```bash
pre-commit install
pre-commit run --all-files
```

---

# ğŸŒ **Production Deployment**

This project is designed to be deployed with:

* **Docker images from GHCR**
* **Ansible deployment automation**
* **Caddy reverse proxy configuration**

API and Worker run as independent containers for scalability.

---

# ğŸ§  **Environment Configuration**

Environment variables are loaded automatically from `.env`:

```
APP_NAME=Starter AI Service
LOG_LEVEL=info
REDIS_URL=redis://redis:6379/0
OPENAI_API_KEY=...
```

Using the Pydantic Settings system:

```python
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    APP_NAME: str
    LOG_LEVEL: str

    model_config = {
        "env_file": ".env",
        "env_file_encoding": "utf-8"
    }
```

---

# ğŸ“ **Future Enhancements**

* Automatic prompt versioning
* Background job scheduler container
* WebSocket support
* OpenTelemetry tracing
* API gateway integration

---

# ğŸ‰ **Summary**

You now have a **clean, modular, production-ready AI microservice**, complete with:

* API + Worker separation
* Full dockerization
* Automated testing
* Automated formatting & linting
* CI/CD + deployment
* Extensible architecture for LLMs, SEO, image tools, prompts, and more
